# EDA, Regression Modeling and More with Seoul Officetel Rentals Data (2011-2021)

## Introduction
## Preprocessing
### Set Hangeul Font, í•œê¸€ í°íŠ¸ ì„¤ì •
#### - For plotting purposes
#### - matplotlib.rc("font",family=font_name)

import matplotlib as mpl
import matplotlib.font_manager as fm 

# Nanum Gothic Coding
# font_path= r"C:\tmp\NanumGothicCoding-Bold.ttf"

# D2Coding
font_path= r"C:\tmp\D2CodingBold-Ver1.3.2-20180524.ttf".replace("\\","/")

font_name= fm.FontProperties(fname=font_path).get_name() # D2Coding

mpl.rc("font",family=font_name)

# =======================================================
import pandas as pd 

path= "./data/"
#csv_2021= "seoul_rental_2021.csv"
csv_2020= "seoul_rental_2020.csv"
csv_2019= "seoul_rental_2019.csv"
csv_2018= "seoul_rental_2018.csv"
csv_2017= "seoul_rental_2017.csv"
csv_2016= "seoul_rental_2016.txt"
csv_2015= "seoul_rental_2015.txt"
#csv_2014= "seoul_rental_2014.txt"
csv_2014_clean= "seoul_rental_2014_clean.txt"
csv_2013= "seoul_rental_2013.txt"
csv_2012= "seoul_rental_2012.txt"
csv_2011= "seoul_rental_2011.txt"

# df_2021= pd.read_csv(path+csv_2021,encoding="cp949")
# df_2021.shape
df_2020= pd.read_csv(path+csv_2020,encoding="cp949")
df_2019= pd.read_csv(path+csv_2019,encoding="cp949")
df_2018= pd.read_csv(path+csv_2018,encoding="cp949")
df_2017= pd.read_csv(path+csv_2017,encoding="cp949")
df_2016= pd.read_csv(path+csv_2016,encoding="utf-8")
df_2015= pd.read_csv(path+csv_2015,encoding="utf-8")
#df_2014= pd.read_csv(path+csv_2014,encoding="utf-8")
df_2013= pd.read_csv(path+csv_2013,encoding="utf-8")
df_2012= pd.read_csv(path+csv_2012,encoding="utf-8")
df_2011= pd.read_csv(path+csv_2011,encoding="utf-8")
# =======================================================
### Merge 10-year records into one dataframe
#### - Check the shape of all the dataframes

# df_list= [df_2020,df_2019,df_2018,df_2017,df_2016,df_2015,df_2014,df_2013,df_2012,df_2011]
# for i,df in enumerate(df_list):
#     year=2020-i
#     print(year,":",df.shape)

df_2014_clean= pd.read_csv(path+csv_2014_clean,encoding="utf-8")
df_2014_clean.shape

df_list= [df_2020,df_2019,df_2018,df_2017,df_2016,df_2015,df_2014_clean,df_2013,df_2012,df_2011]
for i,df in enumerate(df_list):
    year=2020-i
    print(year,":",df.info())
    
# =======================================================
#### - The two unnamed columns are from the year 2014.
#### - tabulation of 1909 rows incorrect; has to be manually adjusted
#### - 2014ë…„ ë‹¨ì§€ëª…ì— ë„ë¡œëª…ë„ í¬í•¨ëœ ë¶€ë¶„ ì§ì ‘ ìˆ˜ì •
#### - 2015: 2931 rows 
#### - 2016: 3054 rows
#### - 2017: 7163 rows
#### - 2018: 6276 rows
#### - 2019: 6811
#### - 2020: 6183 rows
# pd.set_option("display.max_rows",106) # 106 rows with whitespace
# na_idx= df_2014_clean[df_2014_clean["ë„ë¡œëª…"]==" "].index
# df_2014_clean.iloc[na_idx]

# df_2014.isna().sum()

df_list= [df_2020,df_2019,df_2018,df_2017,df_2016,df_2015,df_2014_clean,df_2013,df_2012,df_2011]
df_backup= pd.concat(df_list,ignore_index=True)
df= df_backup.copy()
df.info()
# df.head(1)

# =======================================================
### Columns to be merged/dropped
#### - ë²ˆì§€ (lot number)
#### - ë³¸ë²ˆ (primary lot number)
#### - ë¶€ë²ˆ (secondary lot number)
#### - ë‹¨ì§€ëª… (building/estate name)
#### - ë„ë¡œëª… (street address)
#### The street address is the only address that is legally valid in South Korea since the Road Name Address Act came fully into effect on January 1, 2014. The estate name has additional information and will be merged with the street name. The empty cells of the street address column will be filled the lot number and/or the estate name. The lot number is made up of a primary number hyphenated with a secondary number, e.g., 1237-3.
#### ğŸ‡°ğŸ‡·
#### > ë„ë¡œëª…ì£¼ì†Œë²•ì´ ì „ë©´ì ìœ¼ë¡œ ì‹œí–‰ë˜ë©´ì„œ 2014ë…„ 1ì›” 1ì¼ë¶€í„°ëŠ” í† ì§€ëŒ€ì¥ì„ ì œì™¸í•œ ëª¨ë“  ê³³ì— ë„ë¡œëª…ì£¼ì†Œë§Œì„ ì“¸ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ë²ˆì§€ëŠ” ì œì™¸í•˜ê³  ë„ë¡œëª… ì£¼ì†Œì™€ ë‹¨ì§€ëª…ì„ í™œìš©í•œë‹¤.

### Rename data columns
#### - ì‹œêµ°êµ¬ â†’ district1
#### - ë²ˆì§€ â†’ lot_num
#### - ë³¸ë²ˆ â†’ lot_num_1
#### - ë¶€ë²ˆ â†’ lot_num_2
#### - ë‹¨ì§€ëª… â†’ estate_name
#### - ì „ì›”ì„¸êµ¬ë¶„ â†’ rent_type (lump-sum or monthly)
#### - ì „ìš©ë©´ì (ã¡) â†’ unit_size (mÂ²)
#### - ê³„ì•½ë…„ì›” â†’ sign_yymm
#### - ê³„ì•½ì¼ â†’ sign_dd
#### - ë³´ì¦ê¸ˆ(ë§Œì›) â†’ deposit (in 10,000 won)
#### - ì›”ì„¸(ë§Œì›) â†’ rent_price (in 10,000 won)
#### - ì¸µ â†’ floor
#### - ê±´ì¶•ë…„ë„ â†’ yr_built
#### - ë„ë¡œëª… â†’ str_addr

cols= ["district1","lot_num","lotnum_1","lotnum_2","estate_name","rent_type","unit_size","sign_yymm","sign_dd","deposit","rent_price","floor","yr_built","str_addr"]

df.columns= cols
# df.head(1)
# df.isna().sum()

# import numpy as np 
# nan_index= np.where(df.str_addr.isna())
# nan_index
# nan_index[0]

# =======================================================
### Merge str_addr and estate_name
#### - into new column street_addr, and
#### - drop the two columns
import numpy as np
df["estate_name"]= df["estate_name"].astype(str)
df["str_addr"]= df.str_addr.astype(str)

# str_addr_series= [row["str_addr"].replace("nan","")+row["estate_name"] if row["str_addr"]=="nan" else row["str_addr"]+", "+row["estate_name"] for i,row in df.iterrows()]
# df.insert(0,"street_addr",str_addr_series)
#### ğŸ‡°ğŸ‡·
#### > íƒìƒ‰ ê²°ê³¼ ë„ë¡œëª… ì»¬ëŸ¼ì— whitespaceë§Œ ìˆëŠ” rowê°€ íŒŒì¼ë§ˆë‹¤ ìˆ˜ì²œê°œ ë°œê²¬ë¨. ë¹ˆ cellì€ ë‹¨ì§€ëª…ìœ¼ë¡œ ì±„ì›€
### Fill in empty or whitespaced cells with estate_name
idx_empty_addr= df[df.str_addr==" "].index
idx_empty_addr.shape

# ë„ë¡œëª…ì´ ë¹„ì–´ìˆëŠ” ë ˆì½”ë“œ ì¤‘ ë‹¤ë¥¸ ì—°ë„ íŒŒì¼ì— ë„ë¡œëª…ì´ ê¸°ë¡ë˜ì–´ ìˆìœ¼ë©´ ë³µì‚¬í•˜ì—¬ ì±„ìš´ë‹¤
df["estate_name"]= df.estate_name.str.strip().astype(str)
df["str_addr"]= df.str_addr.str.strip().astype(str)

empty_strt_estate= list(df.iloc[idx_empty_addr].estate_name.unique()) # 261 properties
estate_street_name= df[df.str_addr!=""][["estate_name","str_addr"]].drop_duplicates()
ESTATE_STR_ADDR= {} # KEY estate_name: VALUE street_addr
for i,row in estate_street_name.iterrows():
    # list of estate without street addr
    for es in empty_strt_estate:
        if es in row["estate_name"]:
            ESTATE_STR_ADDR[es]= row.str_addr
            continue

# =======================================================
# ë„ë¡œ ì£¼ì†Œê°€ ì—†ëŠ” ì…€ì— ë‹¨ì§€ëª…ì„ ì±„ì›Œë„£ìŒ.
# 32418 rows 
from timeit import default_timer as timer
start_t= timer()
for i in idx_empty_addr:
    estate_name= df.loc[i,"estate_name"]
    str_addr= ESTATE_STR_ADDR.get(estate_name)
    df.loc[i,"str_addr"]= str_addr if str_addr is not None else estate_name
elapsed_t= timer()-start_t
print(elapsed_t,"seconds")

#### function equivalent to the above
def replace_none(estate_name,str_addr):
    if str_addr is None:
        return estate_name
    else:
        return str_addr
df.loc[idx_empty_addr,"str_addr"]=df.iloc[idx_empty_addr][["estate_name","str_addr"]].apply(lambda x: replace_none(*x),axis=1)#.drop_duplicates()

# =======================================================

# df.isna().sum()

# =======================================================
### Drop unused columns
#### - lot_num
#### - lot_num_2
#### - estate_name
#### - str_addr

df.drop(["lot_num","lotnum_2","estate_name"],axis=1,inplace=True)
# df.head(1)

# =======================================================
### New column district
#### - ì „ì²´ ë°ì´í„°ê°€ ì„œìš¸ ì§€ì—­ì— í•œì •ë˜ì–´ ìˆìœ¼ë¯€ë¡œ "ì„œìš¸íŠ¹ë³„ì‹œ", ë™ ì´ë¦„ ì œê±°

df.insert(0,"district",[val.split()[1] for i,val in df.district1.iteritems() ])
df.head(1)

df.insert(1,"old_div",[f"{val.split()[2]}" for i,val in df.district1.iteritems()])
df.head(1)

# =======================================================
### Drop columns
#### - district1

df.drop("district1",axis=1,inplace=True)
# df.head(1)

# =======================================================
### Data imputation: yr_built
#### - Fill empty cells of yr_built with the median value
#### ğŸ‡°ğŸ‡· - ê±´ì¶•ë…„ë„ê°€ ë¹„ì–´ ìˆëŠ” ê²½ìš° median valueë¡œ ì±„ì›€

#### find the median value for a given column
def find_median(col,df):
    return df[df[col].notna()][col].median()

df.loc[df.yr_built.isna(),"yr_built"]= find_median("yr_built", df) # median: 2013
df["yr_built"]= df.yr_built.astype(int)

df.head(1)
# df.isna().sum()
# df.yr_built.nunique()
# df.yr_built.unique()

# =======================================================
### Create new column sign_date
#### - create `sign_date` from sign_yymm and sign_dd
#### ğŸ‡°ğŸ‡·
#### > ê³„ì•½ë…„ì›”(ì˜ˆ: 202004)ê³¼ ê³„ì•½ì¼(11)ì„ í•©ì³ sign_date (ì˜ˆ: 2020-04-11) ìƒì„±

# df.sign_dd.value_counts()

#### sign_dd ratio 
(df.sign_dd.value_counts()/df.shape[0])

sign_date= pd.to_datetime((df.sign_yymm.astype(str)+df.sign_dd.astype(str)),format="%Y%m%d")
df.insert(7,"sign_date",sign_date)
df.head(1)

# =======================================================
### rent_type ratio
#### ratio of monthly and lump-sum 
df.rent_type.value_counts()

#### ì „ì„¸ ê³„ì•½ ê±´ë¬¼ì˜ ê±´ì¶•ë…„ë„ ë¶„í¬
df[df.rent_type=="ì „ì„¸"]["yr_built"].value_counts()

# df.info()

# ======================================================
### Change dtype of `deposit` to int
#### - First, remove the thousand-separator
#### - and convert to int
df.deposit.astype(str).str.contains(",").sum()
# df["deposit"]= df_backup["ë³´ì¦ê¸ˆ(ë§Œì›)"]
df["deposit"]= df.astype(str).deposit.str.replace(",","").astype(int)

# df= df.convert_dtypes()
# df.dtypes

# =====================================================
### Impute the monthly rent_price for the lump-sum lease

#### - Zero-value cells will be filled with deposit.mode value of the monthly rent_type
#### ğŸ‡°ğŸ‡· >  2021ë…„ 5ì›” ì„œìš¸ ì˜¤í”¼ìŠ¤í…” ì „ì›”ì„¸ ì „í™˜ìœ¨ì€ 4.69%ì´ë©° ì „ì›”ì„¸ ì „í™˜ì‹ì€ ì•„ë˜ì™€ ê°™ë‹¤.
#### ((lump_sum - new_deposit) * 4.69%) / 12 = monthly_rent
#### ì˜¤í”¼ìŠ¤í…” ê°€ê²©ë™í–¥ì¡°ì‚¬ link: https://www.r-one.co.kr/
# deposit_median= df[df.rent_type=="ì›”ì„¸"].deposit.median()#[0]
# df["rent_price_adj"]= ((df.deposit - deposit_median)*.0469)/12
### replace zero cells with the original rent_price for monthly rent type ì›”ì„¸ ê³„ì•½ ê±´ì€ ì›ë˜ì˜ ê°’ìœ¼ë¡œ ëŒ€ì²´í•œë‹¤
# df.loc[df.rent_price_adj<=0,"rent_price_adj"]= df.loc[df.rent_type=="ì›”ì„¸","rent_price"]
# =====================================================

### GPS coordinates for the 25 districts
### - ['ê°•ë‚¨êµ¬', 'ê°•ë™êµ¬', 'ê°•ë¶êµ¬', 'ê°•ì„œêµ¬', 'ê´€ì•…êµ¬', 'ê´‘ì§„êµ¬', 'êµ¬ë¡œêµ¬', 'ê¸ˆì²œêµ¬', 'ë…¸ì›êµ¬',       'ë„ë´‰êµ¬', 'ë™ëŒ€ë¬¸êµ¬', 'ë™ì‘êµ¬', 'ë§ˆí¬êµ¬', 'ì„œëŒ€ë¬¸êµ¬', 'ì„œì´ˆêµ¬', 'ì„±ë™êµ¬', 'ì„±ë¶êµ¬', 'ì†¡íŒŒêµ¬',       'ì–‘ì²œêµ¬', 'ì˜ë“±í¬êµ¬', 'ìš©ì‚°êµ¬', 'ì€í‰êµ¬', 'ì¢…ë¡œêµ¬', 'ì¤‘êµ¬', 'ì¤‘ë‘êµ¬']

coords= [
    (37.5172, 127.0473), #gangnam
    (37.5301, 127.1238), #gangdong
    (37.6396, 127.0257), #gangbuk-gu
    (37.5510, 126.8495),# gangseo-gu
    (37.4784, 126.9516),# gwanak-gu
    (37.5385, 127.0823), #gwangjin-gu 
    (37.4954, 126.8874), #guro-gu
    (37.4519, 126.9020), #geumcheon-gu
    (37.6542, 127.0568), #nowon-gu
    (37.6688, 127.0471), #dobong-gu
(37.5744, 127.0400), #dongdaemun-gu
(37.5124, 126.9393), #dongjak-gu
(37.5638, 126.9084), #mapo-gu
(37.5791, 126.9368), #seodaemun-gu
(37.4837, 127.0324), #seocho-gu
(37.5633, 127.0371), #seongdong-gu
(37.5891, 127.0182), #seongbuk-gu
(37.5145, 127.1066), #songpa-gu
(37.5169, 126.8664), #yangcheon-gu
(37.5264, 126.8962), #yeongdeungpo-gu
    (37.5384, 126.9654), #yongsan-gu
    (37.6027, 126.9291), #eunpyeong-gu
    (37.5730, 126.9794), #jongno-gu
    (37.5641, 126.9979), #jung-gu
    (37.6066, 127.0927), #jungnang-gu
]

DISTRICT_LAT= {}
DISTRICT_LON= {}
for idx,name in enumerate((list(df.district.unique()))):
    DISTRICT_LAT[name]= coords[idx][0]
    DISTRICT_LON[name]= coords[idx][1]

### Add latitude and longitude columns
lat= [DISTRICT_LAT.get(name) for i,name in df["district"].iteritems()]
lon= [DISTRICT_LON.get(name) for i,name in df["district"].iteritems()]

df.insert(1,"latitude",lat)
df.insert(2,"longitude",lon)
df.head(1)
# =====================================================
df.insert(3,"street_addr",df.str_addr)
del df["str_addr"]
df.head(1)

# =====================================================
### separate street names using regular expression
#
# https://stackoverflow.com/questions/43237338/python-regular-expression-split-string-into-numbers-and-text-symbols
import re
re.sub("\(|\)","","(1237-3)") # gives 1237-3

import re
def find_pattern(pat,str_seq):
    # \d+     matches one or more digits
    # \d*\D+  matches zero or more digits followed by one or more non-digits
    # \d+|\D+ matches one or more digits OR one or more non-digits
    return re.search(pat,str_seq).group()

#### split by whitespace \s or
####  one or more digits \d+ 
#ë§ˆê³¡ì¤‘ì•™ë¡œ 161-11, íìŠ¤í…Œì´íŠ¸ì—ì½” ë§ˆê³¡ë‚˜ë£¨ì—­ ë¼ë§ˆë‹¤ì•™ì½”ë¥´ ì„œìš¸ë§ˆê³¡
import re
ser_street= [re.split("\d+|\(",val)[0] for val in df.street_addr.values]
#### longest street name
# max(ser_street,key=len) # ëª©ë™ì¤‘ì•™ë¶ë¡œ

### Add new `street` column
df.insert(3,"street",ser_street)
df.head(1)

#
df[df.street.str.contains("ì²­ë£¡")].street_addr.unique() #ì²­ë£¡_ê¸¸
df[df.street.str.contains("ì§„ê´€")].street_addr.unique() #ì§„ê´€_ë¡œ
df[df.street.str.contains("ë§ˆê³¡ì¤‘ì•™")].street_addr.unique() # ë§ˆê³¡ì¤‘ì•™ë¡œ
df[df.street.str.contains("ìŠ¹ë°©")].street_addr.unique() # ìŠ¹ë°©ê¸¸

### ==========================================
### Numeric encoding
#### - `district`: 4 groups
#### - `old_div`: 272 categories -> 4*4 groups
#### - `floor`: <=10, >10, >20 -> 3 groups
#### - `yr_built`: 70s,80s,90s,00s,10s -> 5 groups 
#### ğŸ‡°ğŸ‡·
#### > categorical ìœ í˜•ì˜ ì»¬ëŸ¼ì€ ìˆ«ìí˜•ìœ¼ë¡œ encodeí•¨

df["district"]= df.district.astype("category")
df["old_div"]= df.district.astype("category")
df["floor"]= df.district.astype("category")
df["yr_built"]= df.district.astype("category")
df.dtypes

import category_encoders as ce
from timeit import default_timer as timer

### ==========================================
### encode `district`
start_t= timer()

# ce_hash.hashing_trick(df[["old_div"]], N=10, cols=['old_div'])
encoder= ce.hashing.HashingEncoder(cols=["district"],return_df=True)
df_enc= encoder.hashing_trick(df[["district","latitude","longitude"]],N=4)
# df_enc.insert(0,"district",df.district)

print("elapsed:",timer()-start_t,"seconds")
df_enc.head(1)

### ==========================================
### encode `old_div`
start_t= timer()
encoder= ce.hashing.HashingEncoder(cols=["old_div"],return_df=True)
df_enc= encoder.hashing_trick(df[["old_div","latitude","longitude"]],N=16)
print("elapsed:",timer()-start_t,"seconds")
df_enc.head(1)

### ==========================================
### encode `floor`
start_t= timer()
encoder= ce.hashing.HashingEncoder(cols=["floor"],return_df=True)
df_enc= encoder.hashing_trick(df[["floor","yr_built"]],N=3)
print("elapsed:",timer()-start_t,"seconds")
df_enc.head(1)

### ==========================================
### encode `yr_built`
start_t= timer()
encoder= ce.hashing.HashingEncoder(cols=["yr_built"],return_df=True)
df_enc= encoder.hashing_trick(df[["yr_built","latitude","longitude"]],N=5)
print("elapsed:",timer()-start_t,"seconds")
df_enc.head(1)

### ==========================================
### Divide the dataset by `rent_type`
#### - Lump-sum: `deposit` is chosen as the target variable.
#### - Monthly: `rent_price` as the target variable.   
#### ğŸ‡°ğŸ‡·
#### > ì„ëŒ€ ìœ í˜•ì— ë”°ë¼ target_variableì´ ë‹¬ë¼ì§€ë¯€ë¡œ ë°ì´í„°ì„¸íŠ¸ë¥¼ ë¶„ë¦¬í•¨

df_lumpsum= df[df.rent_type=="ì „ì„¸"].drop("rent_type",axis=1)
df_monthly= df[df.rent_type=="ì›”ì„¸"].drop("rent_type",axis=1)
# ì „ì„¸ ë°ì´í„°ì„¸íŠ¸ ì¤‘ ì›”ì„¸ê°€ 0ë³´ë‹¤ í° 3ê±´ì€ ê³ ë ¤ ì•ˆ í•¨
# drop rent_price column from df_lumpsum
df_lumpsum.drop("rent_price",axis=1) 
df_lumpsum.shape, df_monthly.shape

df.head(1)
