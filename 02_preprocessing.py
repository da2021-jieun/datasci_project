# EDA, Regression Modeling and More with Seoul Officetel Rentals Data (2011-2021)

## Introduction
## Preprocessing
### Set Hangeul Font, í•œê¸€ í°íŠ¸ ì„¤ì •
#### - For plotting purposes
#### - matplotlib.rc("font",family=font_name)

import matplotlib as mpl
import matplotlib.font_manager as fm 

# Nanum Gothic Coding
# font_path= r"C:\tmp\NanumGothicCoding-Bold.ttf"

# D2Coding
font_path= r"C:\tmp\D2CodingBold-Ver1.3.2-20180524.ttf".replace("\\","/")

font_name= fm.FontProperties(fname=font_path).get_name() # D2Coding

mpl.rc("font",family=font_name)

# =======================================================
import pandas as pd 

path= "./data/"
# csv_2021= "seoul_rental_2021.txt"
csv_2020= "seoul_rental_2020.csv"
csv_2019= "seoul_rental_2019.csv"
csv_2018= "seoul_rental_2018.csv"
csv_2017= "seoul_rental_2017.csv"
csv_2016= "seoul_rental_2016.txt"
csv_2015= "seoul_rental_2015.txt"
csv_2014= "seoul_rental_2014.txt"
csv_2014_clean= "seoul_rental_2014_clean.txt"
csv_2013= "seoul_rental_2013.txt"
csv_2012= "seoul_rental_2012.txt"
csv_2011= "seoul_rental_2011.txt"

# df_2021= pd.read_csv(path+csv_2021,encoding="utf-8")
# df_2021.shape
df_2020= pd.read_csv(path+csv_2020,encoding="cp949")
df_2019= pd.read_csv(path+csv_2019,encoding="cp949")
df_2018= pd.read_csv(path+csv_2018,encoding="cp949")
df_2017= pd.read_csv(path+csv_2017,encoding="cp949")
df_2016= pd.read_csv(path+csv_2016,encoding="utf-8")
df_2015= pd.read_csv(path+csv_2015,encoding="utf-8")
df_2014= pd.read_csv(path+csv_2014,encoding="utf-8")
df_2013= pd.read_csv(path+csv_2013,encoding="utf-8")
df_2012= pd.read_csv(path+csv_2012,encoding="utf-8")
df_2011= pd.read_csv(path+csv_2011,encoding="utf-8")
# =======================================================
### Merge 10-year records into one dataframe
#### - Check the shape of all the dataframes

df_list= [df_2020,df_2019,df_2018,df_2017,df_2016,df_2015,df_2014,df_2013,df_2012,df_2011]
for i,df in enumerate(df_list):
    year=2020-i
    print(year,":",df.shape)
print("="*35)

df_2014_clean= pd.read_csv(path+csv_2014_clean,encoding="utf-8")
# df_2014_clean.shape

df_list= [df_2020,df_2019,df_2018,df_2017,df_2016,df_2015,df_2014_clean,df_2013,df_2012,df_2011]
for i,df in enumerate(df_list):
    year=2020-i
    print(year,":",df.shape)
    
# =======================================================
#### - The two unnamed columns are from the year 2014.
#### - tabulation of 1909 rows incorrect; has to be manually adjusted
#### - 2014ë…„ ë‹¨ì§€ëª…ì— ë„ë¡œëª…ë„ í¬í•¨ëœ ë¶€ë¶„ ì§ì ‘ ìˆ˜ì •
#### - 2015: 2931 rows 
#### - 2016: 3054 rows
#### - 2017: 7163 rows
#### - 2018: 6276 rows
#### - 2019: 6811
#### - 2020: 6183 rows
# pd.set_option("display.max_rows",106) # 106 rows with whitespace
# na_idx= df_2014_clean[df_2014_clean["ë„ë¡œëª…"]==" "].index
# df_2014_clean.iloc[na_idx]

# df_2014.isna().sum()

df_list= [df_2020,df_2019,df_2018,df_2017,df_2016,df_2015,df_2014_clean,df_2013,df_2012,df_2011]
df_backup= pd.concat(df_list,ignore_index=True)
df= df_backup.copy()
df.info()
# df.head(1)

# =======================================================
### Columns to be merged/dropped
#### - ë²ˆì§€ (lot number)
#### - ë³¸ë²ˆ (primary lot number)
#### - ë¶€ë²ˆ (secondary lot number)
#### - ë‹¨ì§€ëª… (building/estate name)
#### - ë„ë¡œëª… (street address)
#### The street address is the only address that is legally valid in South Korea since the Road Name Address Act came fully into effect on January 1, 2014. The estate name has additional information and will be merged with the street name. The empty cells of the street address column will be filled the lot number and/or the estate name. The lot number is made up of a primary number hyphenated with a secondary number, e.g., 1237-3.
#### ğŸ‡°ğŸ‡·
#### > ë„ë¡œëª…ì£¼ì†Œë²•ì´ ì „ë©´ì ìœ¼ë¡œ ì‹œí–‰ë˜ë©´ì„œ 2014ë…„ 1ì›” 1ì¼ë¶€í„°ëŠ” í† ì§€ëŒ€ì¥ì„ ì œì™¸í•œ ëª¨ë“  ê³³ì— ë„ë¡œëª…ì£¼ì†Œë§Œì„ ì“¸ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ë²ˆì§€ëŠ” ì œì™¸í•˜ê³  ë„ë¡œëª… ì£¼ì†Œì™€ ë‹¨ì§€ëª…ì„ í™œìš©í•œë‹¤.

### Rename data columns
#### - ì‹œêµ°êµ¬ â†’ district1
#### - ë²ˆì§€ â†’ lot_num
#### - ë³¸ë²ˆ â†’ lot_num_1
#### - ë¶€ë²ˆ â†’ lot_num_2
#### - ë‹¨ì§€ëª… â†’ estate_name
#### - ì „ì›”ì„¸êµ¬ë¶„ â†’ rent_type (lump-sum or monthly)
#### - ì „ìš©ë©´ì (ã¡) â†’ unit_size (mÂ²)
#### - ê³„ì•½ë…„ì›” â†’ sign_yymm
#### - ê³„ì•½ì¼ â†’ sign_dd
#### - ë³´ì¦ê¸ˆ(ë§Œì›) â†’ deposit (in 10,000 won)
#### - ì›”ì„¸(ë§Œì›) â†’ rent_price (in 10,000 won)
#### - ì¸µ â†’ floor
#### - ê±´ì¶•ë…„ë„ â†’ yr_built
#### - ë„ë¡œëª… â†’ str_addr

cols= ["district1","lot_num","lotnum_1","lotnum_2","estate_name","rent_type","unit_size","sign_yymm","sign_dd","deposit","rent_price","floor","yr_built","str_addr"]

df.columns= cols
# df.head(1)
# df.isna().sum()

# import numpy as np 
# nan_index= np.where(df.str_addr.isna())
# nan_index
# nan_index[0]

# =======================================================
### Merge str_addr and estate_name
#### - into new column street_addr, and
#### - drop the two columns
import numpy as np
df["estate_name"]= df["estate_name"].astype(str).str.strip()
df["str_addr"]= df.str_addr.astype(str).str.strip()
# ë„ë¡œëª…ì´ ë¹„ì–´ìˆëŠ” ë ˆì½”ë“œ ì¤‘ ë‹¤ë¥¸ ì—°ë„ íŒŒì¼ì— ë„ë¡œëª…ì´ ê¸°ë¡ë˜ì–´ ìˆìœ¼ë©´ ë³µì‚¬í•˜ì—¬ ì±„ìš´ë‹¤
# df["estate_name"]= df.estate_name.str.strip().astype(str)
# df["str_addr"]= df.str_addr.str.strip().astype(str)

# str_addr_series= [row["str_addr"].replace("nan","")+row["estate_name"] if row["str_addr"]=="nan" else row["str_addr"]+", "+row["estate_name"] for i,row in df.iterrows()]
# df.insert(0,"street_addr",str_addr_series)
#### ğŸ‡°ğŸ‡·
#### > íƒìƒ‰ ê²°ê³¼ ë„ë¡œëª… ì»¬ëŸ¼ì— whitespaceë§Œ ìˆëŠ” rowê°€ íŒŒì¼ë§ˆë‹¤ ìˆ˜ì²œê°œ ë°œê²¬ë¨. ë¹ˆ cellì€ ë‹¨ì§€ëª…ìœ¼ë¡œ ì±„ì›€
### Fill in empty or whitespaced cells with estate_name
idx_empty_addr= df[df.str_addr==" "].index
idx_empty_addr.shape

empty_strt_estate= list(df.iloc[idx_empty_addr].estate_name.unique()) # 261 properties
estate_street_name= df[df.str_addr!=""][["estate_name","str_addr"]].drop_duplicates()
ESTATE_STR_ADDR= {} # KEY estate_name: VALUE street_addr
for i,row in estate_street_name.iterrows():
    # list of estate without street addr
    for es in empty_strt_estate:
        if es in row["estate_name"]:
            ESTATE_STR_ADDR[es]= row.str_addr
            continue

# =======================================================
# ë„ë¡œ ì£¼ì†Œê°€ ì—†ëŠ” ì…€ì— ë‹¨ì§€ëª…ì„ ì±„ì›Œë„£ìŒ.
# 32418 rows 
from timeit import default_timer as timer
start_t= timer()
for i in idx_empty_addr:
    estate_name= df.loc[i,"estate_name"]
    str_addr= ESTATE_STR_ADDR.get(estate_name)
    df.loc[i,"str_addr"]= str_addr if str_addr is not None else estate_name
elapsed_t= timer()-start_t
print(elapsed_t,"seconds")

#### function equivalent to the above
def replace_none(estate_name,str_addr):
    if str_addr is None:
        return estate_name
    else:
        return str_addr
df.loc[idx_empty_addr,"str_addr"]=df.iloc[idx_empty_addr][["estate_name","str_addr"]].apply(lambda x: replace_none(*x),axis=1)#.drop_duplicates()

# =======================================================

# df.isna().sum()

# =======================================================
### Drop unused columns
#### - lot_num
#### - lot_num_2
#### - estate_name
#### - str_addr

df.drop(["lot_num","lotnum_2","estate_name"],axis=1,inplace=True)
# df.head(1)

# =======================================================
### New column district
#### - ì „ì²´ ë°ì´í„°ê°€ ì„œìš¸ ì§€ì—­ì— í•œì •ë˜ì–´ ìˆìœ¼ë¯€ë¡œ "ì„œìš¸íŠ¹ë³„ì‹œ", ë™ ì´ë¦„ ì œê±°

df.insert(0,"district",[val.split()[1] for i,val in df.district1.iteritems() ])
df.head(1)

df.insert(1,"old_div",[f"{val.split()[2]}" for i,val in df.district1.iteritems()])
df.head(1)

# =======================================================
### Drop columns
#### - district1

df.drop("district1",axis=1,inplace=True)
# df.head(1)

# =======================================================
### Data imputation: yr_built
#### - Fill empty cells of yr_built with the median value
#### ğŸ‡°ğŸ‡· - ê±´ì¶•ë…„ë„ê°€ ë¹„ì–´ ìˆëŠ” ê²½ìš° median valueë¡œ ì±„ì›€

#### find the median value for a given column
def find_median(col,df):
    return df[df[col].notna()][col].median()

df.loc[df.yr_built.isna(),"yr_built"]= find_median("yr_built", df) # median: 2013
df["yr_built"]= df.yr_built.astype(int)

df.head(1)
# df.isna().sum()
# df.yr_built.nunique()
# df.yr_built.unique()

# =======================================================
### Create new column sign_date
#### - create `sign_date` from sign_yymm and sign_dd
#### ğŸ‡°ğŸ‡·
#### > ê³„ì•½ë…„ì›”(ì˜ˆ: 202004)ê³¼ ê³„ì•½ì¼(11)ì„ í•©ì³ sign_date (ì˜ˆ: 2020-04-11) ìƒì„±

# df.sign_dd.value_counts()

#### sign_dd ratio 
(df.sign_dd.value_counts()/df.shape[0])

sign_date= pd.to_datetime((df.sign_yymm.astype(str)+df.sign_dd.astype(str)),format="%Y%m%d")
df.insert(7,"sign_date",sign_date)
df.head(1)

# =======================================================
### rent_type ratio
#### ratio of monthly and lump-sum 
df.rent_type.value_counts()

#### ì „ì„¸ ê³„ì•½ ê±´ë¬¼ì˜ ê±´ì¶•ë…„ë„ ë¶„í¬
df[df.rent_type=="ì „ì„¸"]["yr_built"].value_counts()

# df.info()

# ======================================================
### Change dtype of `deposit` to int
#### - First, remove the thousand-separator
#### - and convert to int
df.deposit.astype(str).str.contains(",").sum()
# df["deposit"]= df_backup["ë³´ì¦ê¸ˆ(ë§Œì›)"]
df["deposit"]= df.astype(str).deposit.str.replace(",","").astype(int)

### =====================================================
### Change dtype of `lotnum_1`,`sign_yymm`,`sign_dd`,`rent_price`,`floor` to int32
import numpy as np
df.lotnum_1= df.lotnum_1.astype(int)
df.sign_yymm= df.sign_yymm.astype(int)
df.sign_dd= df.sign_dd.astype(int)
df.unit_size= df.unit_size.astype(np.float32)
df.rent_price= df.rent_price.astype(int)
df.floor= df.floor.astype(int)

# df= df.convert_dtypes()
# df.dtypes

### ===============================================
### ============== basic statistics ==============
### ===============================================
### dataset shape: (284785 rows, 13 columns)
## 0   district    284785 non-null  object        
#  1   old_div     284785 non-null  object        
#  2   lotnum_1    284785 non-null  int32         
#  3   rent_type   284785 non-null  object        
#  4   unit_size   284785 non-null  float32       
#  5   sign_yymm   284785 non-null  int32         
#  6   sign_dd     284785 non-null  int32         
#  7   sign_date   284785 non-null  datetime64[ns]
#  8   deposit     284785 non-null  int32         
#  9   rent_price  284785 non-null  int32         
#  10  floor       284785 non-null  int32         
#  11  yr_built    284785 non-null  int32         
#  12  str_addr    284785 non-null  object 
print(df.shape)

# =============================================
### Number of missing values
# district      0
# old_div       0
# lotnum_1      0
# rent_type     0
# unit_size     0
# sign_yymm     0
# sign_dd       0
# sign_date     0
# deposit       0
# rent_price    0
# floor         0
# yr_built      0
# str_addr      0
print(df.isna().sum())

# =============================================
### column `district`
print("The district names:\n",df.district.unique())
print("="*50)
print("The number of the districts:",df.district.nunique())
print("="*50)
print(f"The occurrence ratio (%) of the districts:\n{('=')*45}\n{np.round(df.district.value_counts()/df.shape[0]*100,2)}")

# =============================================
### column `old_div`
print("The old_div (ë™) names:\n",df.old_div.unique())
print("="*50)
print("The number of ë™ :",df.old_div.nunique()) # 272 
print("="*50)
print(f"The occurrence of ë™:\n{('=')*45}\n{df.old_div.value_counts()}")

# =============================================
### Column `rent_type`
# Rent type:
# =============================================
# ì›”ì„¸    153970
# ì „ì„¸    130815
print(f"Rent type:\n{('=')*15}\n{df.rent_type.value_counts()}")

### =============================================
### Column `sign_date`
### - year of contract
### - month of contract
# ======================
# Year of Contract:
# ======================
# 2020    50310
# 2019    48053
# 2018    39927
# 2017    34668
# 2016    27497
# 2015    24528
# 2014    20699
# 2013    16151
# 2012    12482
# 2011    10454
# 2010       16
print(f"Year of Contract:\n{('=')*22}\n{df.sign_date.dt.isocalendar().year.value_counts()}")

# ======================
# Month of Contract:
# ======================
# 1     28815
# 2     28021
# 12    25430
# 8     24348
# 7     24317
# 3     24055
# 6     22397
# 10    22342
# 5     21672
# 11    21588
# 4     21132
# 9     20668
print(f"Month of Contract:\n{('=')*22}\n{df.sign_date.dt.month.value_counts()}")

# =============================================
### Column `deposit`
# deposit (in 10,000 won)
# =======================
# count    284785.000000
# mean       9862.980750
# std       10813.885617
# min          20.000000
# 25%        1500.000000
# 50%        6500.000000
# 75%       15000.000000
# max      554100.000000
print(df.deposit.describe())


# =============================================
### Column `rent_price`
### - Lump-sum lease is not considered
### - rent_price (in 10,000 won)
# count    153970.000000
# mean         53.417523
# std          29.123966
# min           1.000000
# 25%          40.000000
# 50%          50.000000
# 75%          60.000000
# max        2123.000000
print(df[df.rent_type=="ì›”ì„¸"].rent_price.describe())

# =============================================
### Column `unit_size`
# Unit size (mÂ²):
# count    284785.000000
# mean         30.842197
# std          18.669453
# min           3.400000
# 25%          19.930000
# 50%          24.910000
# 75%          32.150002
# max         445.119995
df.unit_size.describe()

# =============================================
### Column `floor`
# count    284785.000000
# mean          7.913798
# std           4.922598
# min           1.000000
# 25%           4.000000
# 50%           7.000000
# 75%          11.000000
# max          65.000000
df.floor.describe()

# =============================================
### Prior to data imputation on 8,476 empty cells
### Column ê±´ì¶•ë…„ë„
# count    276309.000000
# mean       2010.333116
# std           6.434324
# min        1972.000000
# 25%        2004.000000
# 50%        2013.000000
# 75%        2016.000000
# max        2021.000000
df_backup[df_backup.ê±´ì¶•ë…„ë„.notna()].ê±´ì¶•ë…„ë„.describe()

### Column `yr_built` (after data imputation)
# count    284785.000000
# mean       2010.412490
# std           6.354031
# min        1972.000000
# 25%        2004.000000
# 50%        2013.000000
# 75%        2016.000000
# max        2021.000000
df.yr_built.describe()

### ===================================================
### EDA
import matplotlib.pyplot as plt 
import seaborn as sns 
plt.style.use("ggplot")

# ==================== Plots 1/3 ====================
### - seaborn.jointplot() for numerical vars
### - unit_size, deposit, rent_type
grid= sns.jointplot(data=df,x="unit_size",y="deposit",hue="rent_type")
# grid.fig.subtitle(f"Deposit w.r.t. Unit_Size\nì „ìš©ë©´ì (mÂ²) ëŒ€ë¹„ ë³´ì¦ê¸ˆ(ë§Œì›)")#,kind="scatter",height=9)
# plt.title(f"Deposit w.r.t. Unit_Size\nì „ìš©ë©´ì (mÂ²) ëŒ€ë¹„ ë³´ì¦ê¸ˆ(ë§Œì›)")
plt.tight_layout()
plt.show()

# ==================== Plots 2/3 ====================
### Distribution of Districts along with sign_year
### - seaborn.displot
# add column: contract year
df["sign_year"]= df.sign_date.dt.year.astype(int)
# fig,ax= plt.subplots(figsize=(22,5))
sns.displot(data=df,x="district",hue="sign_year",multiple="stack",shrink=.8, aspect=18/6) # "shrinking" the bars is helpful to emphasize the categorical nature of the axis # stat="density": when the subsets have unequal numbers of observations, comparing their distributions in terms of counts may not be ideal. One solution is to normalize the counts using the stat parameter
plt.ylabel("number of contracts")
plt.title(f"Distribution of Districts\ní–‰ì •êµ¬ë³„ ê³„ì•½ ê±´ìˆ˜")
plt.show()

# ==================== Plots 3/3 ====================
### - seaborn.boxplot()
### ===================
# fivethirtyeight, ggplot, tableau-colorblind10, Solarize_Light2, seaborn-poster, bmh, grayscale, seaborn-talk, seaborn-darkgrid
plt.style.use("tableau-colorblind10")
plt.figure(figsize=(10,5))
top_districts= (df[df.rent_type=="ì›”ì„¸"].district.value_counts().head(8).index.values)
sns.boxplot(x="rent_price",y="district",data=\
            df[df.district.isin(top_districts)],orient="h")
plt.xlabel("Monthly Rent (in â‚©10,000)")
plt.ylabel("District")
plt.tight_layout()
plt.title(f"Rent Distribution in 8 Districts with Most Leases\nì„ì°¨ê³„ì•½ì´ ê°€ì¥ ë¹ˆë²ˆí•œ í–‰ì •êµ¬ 8ê³³ì˜ ì›”ì„¸ ë¶„í¬") # ğŸ‡°ğŸ‡·
plt.margins()
plt.grid()
plt.show()

# =====================================================
### Impute the monthly rent_price for the lump-sum lease

#### - Zero-value cells will be filled with deposit.mode value of the monthly rent_type
#### ğŸ‡°ğŸ‡· >  2021ë…„ 5ì›” ì„œìš¸ ì˜¤í”¼ìŠ¤í…” ì „ì›”ì„¸ ì „í™˜ìœ¨ì€ 4.69%ì´ë©° ì „ì›”ì„¸ ì „í™˜ì‹ì€ ì•„ë˜ì™€ ê°™ë‹¤.
#### ((lump_sum - new_deposit) * 4.69%) / 12 = monthly_rent
#### ì˜¤í”¼ìŠ¤í…” ê°€ê²©ë™í–¥ì¡°ì‚¬ link: https://www.r-one.co.kr/
# deposit_median= df[df.rent_type=="ì›”ì„¸"].deposit.median()#[0]
# df["rent_price_adj"]= ((df.deposit - deposit_median)*.0469)/12
### replace zero cells with the original rent_price for monthly rent type ì›”ì„¸ ê³„ì•½ ê±´ì€ ì›ë˜ì˜ ê°’ìœ¼ë¡œ ëŒ€ì²´í•œë‹¤
# df.loc[df.rent_price_adj<=0,"rent_price_adj"]= df.loc[df.rent_type=="ì›”ì„¸","rent_price"]
# =====================================================

### GPS coordinates for the 25 districts
### - ['ê°•ë‚¨êµ¬', 'ê°•ë™êµ¬', 'ê°•ë¶êµ¬', 'ê°•ì„œêµ¬', 'ê´€ì•…êµ¬', 'ê´‘ì§„êµ¬', 'êµ¬ë¡œêµ¬', 'ê¸ˆì²œêµ¬', 'ë…¸ì›êµ¬',       'ë„ë´‰êµ¬', 'ë™ëŒ€ë¬¸êµ¬', 'ë™ì‘êµ¬', 'ë§ˆí¬êµ¬', 'ì„œëŒ€ë¬¸êµ¬', 'ì„œì´ˆêµ¬', 'ì„±ë™êµ¬', 'ì„±ë¶êµ¬', 'ì†¡íŒŒêµ¬',       'ì–‘ì²œêµ¬', 'ì˜ë“±í¬êµ¬', 'ìš©ì‚°êµ¬', 'ì€í‰êµ¬', 'ì¢…ë¡œêµ¬', 'ì¤‘êµ¬', 'ì¤‘ë‘êµ¬']

coords= [
    (37.5172, 127.0473), #gangnam
    (37.5301, 127.1238), #gangdong
    (37.6396, 127.0257), #gangbuk-gu
    (37.5510, 126.8495),# gangseo-gu
    (37.4784, 126.9516),# gwanak-gu
    (37.5385, 127.0823), #gwangjin-gu 
    (37.4954, 126.8874), #guro-gu
    (37.4519, 126.9020), #geumcheon-gu
    (37.6542, 127.0568), #nowon-gu
    (37.6688, 127.0471), #dobong-gu
(37.5744, 127.0400), #dongdaemun-gu
(37.5124, 126.9393), #dongjak-gu
(37.5638, 126.9084), #mapo-gu
(37.5791, 126.9368), #seodaemun-gu
(37.4837, 127.0324), #seocho-gu
(37.5633, 127.0371), #seongdong-gu
(37.5891, 127.0182), #seongbuk-gu
(37.5145, 127.1066), #songpa-gu
(37.5169, 126.8664), #yangcheon-gu
(37.5264, 126.8962), #yeongdeungpo-gu
    (37.5384, 126.9654), #yongsan-gu
    (37.6027, 126.9291), #eunpyeong-gu
    (37.5730, 126.9794), #jongno-gu
    (37.5641, 126.9979), #jung-gu
    (37.6066, 127.0927), #jungnang-gu
]

DISTRICT_LAT= {}
DISTRICT_LON= {}
for idx,name in enumerate((list(df.district.unique()))):
    DISTRICT_LAT[name]= coords[idx][0]
    DISTRICT_LON[name]= coords[idx][1]

### Add latitude and longitude columns
lat= [DISTRICT_LAT.get(name) for i,name in df["district"].iteritems()]
lon= [DISTRICT_LON.get(name) for i,name in df["district"].iteritems()]

df.insert(1,"latitude",lat)
df.insert(2,"longitude",lon)
df.head(1)
# =====================================================
df.insert(3,"street_addr",df.str_addr)
del df["str_addr"]
df.head(1)

# =====================================================
### separate street names using regular expression
#
# https://stackoverflow.com/questions/43237338/python-regular-expression-split-string-into-numbers-and-text-symbols
import re
re.sub("\(|\)","","(1237-3)") # gives 1237-3

import re
def find_pattern(pat,str_seq):
    # \d+     matches one or more digits
    # \d*\D+  matches zero or more digits followed by one or more non-digits
    # \d+|\D+ matches one or more digits OR one or more non-digits
    return re.search(pat,str_seq).group()

#### split by whitespace \s or
####  one or more digits \d+ 
#ë§ˆê³¡ì¤‘ì•™ë¡œ 161-11, íìŠ¤í…Œì´íŠ¸ì—ì½” ë§ˆê³¡ë‚˜ë£¨ì—­ ë¼ë§ˆë‹¤ì•™ì½”ë¥´ ì„œìš¸ë§ˆê³¡
import re
ser_street= [re.split("\d+|\(",val)[0] for val in df.street_addr.values]
#### longest street name
# max(ser_street,key=len) # ëª©ë™ì¤‘ì•™ë¶ë¡œ

### Add new `street` column
df.insert(3,"street",ser_street)
df.head(1)

#
df[df.street.str.contains("ì²­ë£¡")].street_addr.unique() #ì²­ë£¡_ê¸¸
df[df.street.str.contains("ì§„ê´€")].street_addr.unique() #ì§„ê´€_ë¡œ
df[df.street.str.contains("ë§ˆê³¡ì¤‘ì•™")].street_addr.unique() # ë§ˆê³¡ì¤‘ì•™ë¡œ
df[df.street.str.contains("ìŠ¹ë°©")].street_addr.unique() # ìŠ¹ë°©ê¸¸

### ==========================================
### Numeric encoding
#### - `district`: 4 groups
#### - `old_div`: 272 categories -> 4*4 groups
#### - `floor`: <=10, >10, >20 -> 3 groups
#### - `yr_built`: 70s,80s,90s,00s,10s -> 5 groups 
#### ğŸ‡°ğŸ‡·
#### > categorical ìœ í˜•ì˜ ì»¬ëŸ¼ì€ ìˆ«ìí˜•ìœ¼ë¡œ encodeí•¨

df["district"]= df.district.astype("category")
df["old_div"]= df.district.astype("category")
df["floor"]= df.district.astype("category")
df["yr_built"]= df.district.astype("category")
df.dtypes

import category_encoders as ce
from timeit import default_timer as timer

### ==========================================
### encode `district`
start_t= timer()

# ce_hash.hashing_trick(df[["old_div"]], N=10, cols=['old_div'])
encoder= ce.hashing.HashingEncoder(cols=["district"],return_df=True)
df_enc= encoder.hashing_trick(df[["district","latitude","longitude"]],N=4)
# df_enc.insert(0,"district",df.district)

print("elapsed:",timer()-start_t,"seconds")
df_enc.head(1)

### ==========================================
### encode `old_div`
start_t= timer()
encoder= ce.hashing.HashingEncoder(cols=["old_div"],return_df=True)
df_enc= encoder.hashing_trick(df[["old_div","latitude","longitude"]],N=16)
print("elapsed:",timer()-start_t,"seconds")
df_enc.head(1)

### ==========================================
### encode `floor`
start_t= timer()
encoder= ce.hashing.HashingEncoder(cols=["floor"],return_df=True)
df_enc= encoder.hashing_trick(df[["floor","yr_built"]],N=3)
print("elapsed:",timer()-start_t,"seconds")
df_enc.head(1)

### ==========================================
### encode `yr_built`
start_t= timer()
encoder= ce.hashing.HashingEncoder(cols=["yr_built"],return_df=True)
df_enc= encoder.hashing_trick(df[["yr_built","latitude","longitude"]],N=5)
print("elapsed:",timer()-start_t,"seconds")
df_enc.head(1)

### ==========================================
### Divide the dataset by `rent_type`
#### - Lump-sum: `deposit` is chosen as the target variable.
#### - Monthly: `rent_price` as the target variable.   
#### ğŸ‡°ğŸ‡·
#### > ì„ëŒ€ ìœ í˜•ì— ë”°ë¼ target_variableì´ ë‹¬ë¼ì§€ë¯€ë¡œ ë°ì´í„°ì„¸íŠ¸ë¥¼ ë¶„ë¦¬í•¨

df_lumpsum= df[df.rent_type=="ì „ì„¸"].drop("rent_type",axis=1)
df_monthly= df[df.rent_type=="ì›”ì„¸"].drop("rent_type",axis=1)
# ì „ì„¸ ë°ì´í„°ì„¸íŠ¸ ì¤‘ ì›”ì„¸ê°€ 0ë³´ë‹¤ í° 3ê±´ì€ ê³ ë ¤ ì•ˆ í•¨
# drop rent_price column from df_lumpsum
df_lumpsum.drop("rent_price",axis=1) 
df_lumpsum.shape, df_monthly.shape

df.head(1)
